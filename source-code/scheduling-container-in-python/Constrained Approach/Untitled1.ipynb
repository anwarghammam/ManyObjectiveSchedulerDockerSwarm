{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed17b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HOSTNAME', 'node-01', 'node-02', 'node-03']\n",
      "['HOSTNAME', 'node-01', 'node-02', 'node-03']\n",
      "['ID', 'p70y0466kv3yd5itzk0hfwprp', 'snxgjfxh13e6jp50dpvaowvoz', 'pmpv7tqklpovk8u96raxqhbvx']\n",
      "['p70y0466kv3yd5itzk0hfwprp', 'snxgjfxh13e6jp50dpvaowvoz', 'pmpv7tqklpovk8u96raxqhbvx']\n",
      "['manager', 'worker', 'worker']\n",
      "['p_cadvisor.p70y0466kv3yd5itzk0hfwprp.2gnor717lidoowrh2c5c1fqz3', 'audio', 'infotainment', 'climate', 'prediction', 'camera', 'gps', 'edgeHub', 'yolo', 'edgeAgent', 'p_cadvisor.snxgjfxh13e6jp50dpvaowvoz.peex0y6q6ode8zfj8ux1aukr2']\n",
      "None\n",
      "['cbedb']\n",
      "None\n",
      "None\n",
      "None\n",
      "['api']\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[]\n",
      "['HOSTNAME', 'node-01', 'node-02', 'node-03']\n",
      "['ID', 'p70y0466kv3yd5itzk0hfwprp', 'snxgjfxh13e6jp50dpvaowvoz', 'pmpv7tqklpovk8u96raxqhbvx']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Aug 30 13:11:51 2020\n",
    "\n",
    "@author: User\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import yaml\n",
    "import json\n",
    "all1={}\n",
    "\n",
    "\n",
    "#NUMBER OF NODES BY CLUSTER\n",
    "\n",
    "\n",
    "class Data:\n",
    "\n",
    "\n",
    "    def get_nodes(self):\n",
    "\n",
    "        machines=[]\n",
    "\n",
    "        with  open(r\"./test3.txt\",'w') as file :\n",
    "\n",
    "\n",
    "            #cmd = ('docker-machine ssh worker1 docker node ls').split()\n",
    "            cmd = (' ssh pi@node-01 docker node ls').split()\n",
    "\n",
    "            p = subprocess.Popen(cmd,stdout=file)\n",
    "            output, errors = p.communicate()\n",
    "            \n",
    "\n",
    "\n",
    "        with open(r\"./test3.txt\",'r') as file:\n",
    "\n",
    "\n",
    "            for line in file:\n",
    "\n",
    "                line=line.replace(\"*\",'')\n",
    "                groupe=line.split()\n",
    "                machines.append(groupe[1])\n",
    "\n",
    "        print(machines)\n",
    "        del machines[0]\n",
    "        return machines\n",
    "    def get_nodes_Id(self):\n",
    "        machines=self.get_nodes()\n",
    "        machines_ids=[]\n",
    "        roles=[]\n",
    "        with open(r\"./test3.txt\",'r') as file:\n",
    "\n",
    "\n",
    "            for line in file:\n",
    "\n",
    "                line=line.replace(\"*\",'')\n",
    "                groupe=line.split()\n",
    "                machines_ids.append(groupe[0])\n",
    "\n",
    "        print(machines_ids)\n",
    "        del machines_ids[0]\n",
    "        return machines_ids\n",
    "\n",
    "    def get_data(self):\n",
    "        machines=self.get_nodes()\n",
    "        containers=[]\n",
    "        initial_state=[]\n",
    "        images=[]\n",
    "        roles=[]\n",
    "        roles.append(\"manager\")\n",
    "        for i in range(len(machines)-1):\n",
    "            roles.append('worker')\n",
    "\n",
    "        for i,machine in enumerate(machines) :\n",
    "            containers1=[]\n",
    "            images1=[]\n",
    "        #please change this path with the right one for you\n",
    "            with  open(r\"./test3.txt\",'w') as file :\n",
    "                \n",
    "                cmd = ('ssh pi@'+str(machine)+' docker ps ').split()\n",
    "\n",
    "                p = subprocess.Popen(cmd,stdout=file)\n",
    "                output, errors = p.communicate()\n",
    "            with open(r\"./test3.txt\",'r') as file:\n",
    "\n",
    "                for line in file:\n",
    "\n",
    "                    groupe=line.split()\n",
    "\n",
    "                    containers1.append(groupe[-1])\n",
    "                    images1.append(groupe[1])\n",
    "\n",
    "            containers1=containers1[1:]\n",
    "            images1=images1[1:]\n",
    "\n",
    "\n",
    "            if( 'carlosedp/rpi-cadvisor:latest' in images1):\n",
    "                del containers1[images1.index('carlosedp/rpi-cadvisor:latest')]\n",
    "                del images1[images1.index('carlosedp/rpi-cadvisor:latest')]\n",
    "            if( 'anwargh/grafana:vlast' in images1):\n",
    "                del containers1[images1.index('anwargh/grafana:vlast')]\n",
    "                del images1[images1.index('anwargh/grafana:vlast')]\n",
    "            if( 'jmb12686/node-exporter:latest' in images1):\n",
    "                del containers1[images1.index('jmb12686/node-exporter:latest')]\n",
    "                del images1[images1.index('jmb12686/node-exporter:latest')]\n",
    "            if( 'prom/alertmanager:latest' in images1):\n",
    "                del containers1[images1.index('prom/alertmanager:latest')]\n",
    "                del images1[images1.index('prom/alertmanager:latest')]\n",
    "\n",
    "            if( 'anwargh/prometheus:arch64' in images1):\n",
    "                del containers1[images1.index('anwargh/prometheus:arch64')]\n",
    "                del images1[images1.index('anwargh/prometheus:arch64')]\n",
    "\n",
    "            if( 'anwargh/prometheus:arch32' in images1):\n",
    "                del containers1[images1.index('anwargh/prometheus:arch32')]\n",
    "                del images1[images1.index('anwargh/prometheus:arch32')]\n",
    "\n",
    "\n",
    "\n",
    "            for container in containers1:\n",
    "\n",
    "                containers.append(container)\n",
    "                initial_state.append(i)\n",
    "\n",
    "            for img in images1:\n",
    "\n",
    "                images.append(img)\n",
    "\n",
    "\n",
    "        return images,containers,roles,initial_state,machines\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def updateDockerCompose(self,containers,images,state,machines,file):\n",
    "        services_to_shutdown=[]\n",
    "        eliminate=[]\n",
    "        with open(r'DockerComposeFiles/docker-compose.yml') as file2:\n",
    "\n",
    "            compose = yaml.load(file2,Loader=yaml.FullLoader)\n",
    "\n",
    "        keys=list(compose['services'].keys())\n",
    "        print (keys)\n",
    "        print\n",
    "        \n",
    "        for i in range(len(state)):\n",
    "            if (state[i]!=-1):\n",
    "                print(images[i],\" \",containers[i].name)\n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "        print() \n",
    "        \n",
    "        for i,con  in enumerate(images) :\n",
    "\n",
    "            for j,dict in enumerate(compose['services']):\n",
    "                #print(keys[j])\n",
    "                \n",
    "\n",
    "                if (str(str(keys[j])+'.') in str(containers[i].name)):\n",
    "                    print('fel condition')\n",
    "                    print(str(compose['services'][dict]['image']),con,str(keys[j])+'.',str(containers[i].name))\n",
    "                    \n",
    "                    \n",
    "                    if (state[i]!=-1):\n",
    "                        \n",
    "                       # print(dict)\n",
    "\n",
    "\n",
    "                        name='node.hostname == '+str(machines[state[i]].name)\n",
    "                        compose['services'][dict].update({'deploy': {'placement': {'constraints':  [ name ]}}})\n",
    "\n",
    "                    else:\n",
    "                        print('-1')\n",
    "                        print(str(compose['services'][dict]['image']),con,str(keys[j])+'.',str(containers[i].name))\n",
    "                        \n",
    "                        eliminate.append(dict)\n",
    "                        services_to_shutdown.append('p_'+str(keys[j]))\n",
    "\n",
    "        print(services_to_shutdown)  \n",
    "\n",
    "        print(eliminate)           \n",
    "        for dict in eliminate:\n",
    "            \n",
    "            del(compose['services'][dict])\n",
    "            \n",
    "        with open(file,'w') as file1:\n",
    "\n",
    "            yaml.dump(compose,file1)\n",
    "\n",
    "\n",
    "        cmd = (\"docker-machine scp localhost:\"+str(file)+\"  docker@\"+str(machines[0].name)+\":. \").split()\n",
    "\n",
    "        p = subprocess.Popen(cmd)\n",
    "        output, errors = p.communicate()\n",
    "\n",
    "        cmd = ('docker-machine ssh '+str(machines[0].name)+' docker stack deploy -c updated-docker-compose.yml p ').split()\n",
    "\n",
    "        p = subprocess.Popen(cmd)\n",
    "        output, errors = p.communicate()\n",
    "\n",
    "        return (services_to_shutdown)\n",
    "\n",
    "\n",
    "\n",
    "        # cmd = ('ssh root@manager docker stack deploy --compose-file docker-compose1.yml p1 ').split()\n",
    "\n",
    "        # p = subprocess.Popen(cmd)\n",
    "        # output, errors = p.communicate()\n",
    "\n",
    "        return (services_to_shutdown)\n",
    "\n",
    "\n",
    "\n",
    "    def get_dependencies(self,images,containers):\n",
    "\n",
    "        all_dependencies=[]\n",
    "    #images,containers,initial_state,machines=get_data()\n",
    "        # cmd = ('scp root@manager:docker-compose.yml /home/anwar/Desktop').split()\n",
    "\n",
    "        # p = subprocess.Popen(cmd)\n",
    "        # output, errors = p.communicate()\n",
    "        with open(r'DockerComposeFiles/docker-compose.yml') as file:\n",
    "\n",
    "\n",
    "            compose = yaml.load(file,Loader=yaml.FullLoader)\n",
    "\n",
    "            for dict in compose['services']:\n",
    "                key=[]\n",
    "\n",
    "                print(compose['services'][dict].get('depends_on'))\n",
    "                if((compose['services'][dict].get('depends_on') is not None)):\n",
    "\n",
    "\n",
    "                    key=[]\n",
    "                    for k,con in enumerate(containers):\n",
    "\n",
    "                        if (str(dict) in str(con)) :\n",
    "                            key.append(k)\n",
    "\n",
    "\n",
    "                    dependencies=compose['services'][dict]['depends_on']\n",
    "                # print(dependencies)\n",
    "                    images1=[]\n",
    "                    for dep in dependencies:\n",
    "                        images1.append(compose['services'][dep]['image'])\n",
    "                # print(images)\n",
    "                    for dep in images1:\n",
    "\n",
    "                        for j,con in enumerate(images):\n",
    "\n",
    "                            for k in key:\n",
    "\n",
    "                                if (str(dep) in str(con)) and ((k,j) not in all_dependencies):\n",
    "                                    all_dependencies.append((k,j))\n",
    "\n",
    "                if((compose['services'][dict].get('links') is not None)):\n",
    "\n",
    "\n",
    "                    key=[]\n",
    "                    for k,con in enumerate(containers):\n",
    "\n",
    "                        if (str(dict) in str(con)) :\n",
    "                            key.append(k)\n",
    "\n",
    "\n",
    "                    dependencies=compose['services'][dict]['links']\n",
    "                # print(dependencies)\n",
    "                    images1=[]\n",
    "                    for dep in dependencies:\n",
    "                        images1.append(compose['services'][dep]['image'])\n",
    "                # print(images)\n",
    "                    for dep in images1:\n",
    "\n",
    "                        for j,con in enumerate(images):\n",
    "\n",
    "                            for k in key:\n",
    "\n",
    "                                if (str(dep) in str(con)) and ((k,j) not in all_dependencies):\n",
    "                                    all_dependencies.append((k,j))\n",
    "\n",
    "\n",
    "\n",
    "                # if((compose['services'][dict].get('links') is not None)):\n",
    "                #     image=compose['services'][dict]['image']\n",
    "                #     for k,con in enumerate(containers):\n",
    "                #         if (str(image) in str(con)):\n",
    "                #             key=k\n",
    "\n",
    "                #     dependencies=compose['services'][dict]['links']\n",
    "                #     images=[]\n",
    "                #     for dep in dependencies:\n",
    "                #         images.append(compose['services'][dep]['image'])\n",
    "                #     for dep in images:\n",
    "                #         for j,con in enumerate(containers):\n",
    "                #             if (str(dep) in str(con)) and  ((key,j) not in all_dependencies):\n",
    "                #                 all_dependencies.append((key,j))\n",
    "\n",
    "        return (all_dependencies)\n",
    "\n",
    "\n",
    "    def get_constraints(self,machines,roles,images):\n",
    "\n",
    "\n",
    "        with open(r'DockerComposeFiles/docker-compose.yml') as file:\n",
    "            compose = yaml.load(file,Loader=yaml.FullLoader)\n",
    "            constraints=[]\n",
    "            for dict in compose['services']:\n",
    "\n",
    "                constraints.append(\"chey\")\n",
    "\n",
    "\n",
    "            for dict in compose['services']:\n",
    "\n",
    "                if(compose['services'][dict].get('image') in images):\n",
    "\n",
    "                    container_index=images.index(compose['services'][dict].get('image'))\n",
    "\n",
    "                else:\n",
    "\n",
    "                    image_name=compose['services'][dict].get('image')+\":latest\"\n",
    "                    container_index=images.index(image_name)\n",
    "\n",
    "                if((compose['services'][dict].get('deploy') is  None)):\n",
    "                    print(container_index)\n",
    "                    constraints[container_index]='NA'\n",
    "\n",
    "\n",
    "\n",
    "                else:\n",
    "\n",
    "\n",
    "                    constraint=compose['services'][dict]['deploy']['placement']['constraints'][0]\n",
    "\n",
    "\n",
    "                    if (\"node.hostname\" in constraint):\n",
    "                        index=constraint.index('==')\n",
    "\n",
    "                        name=constraint[index+3:]\n",
    "\n",
    "                        mach=machines.index(name)\n",
    "\n",
    "\n",
    "                        constraints[container_index]=mach\n",
    "\n",
    "                    if (\"node.role\" in constraint):\n",
    "                        tuple=[]\n",
    "                        if(\"manager\" in constraint):\n",
    "\n",
    "                            for i,rol in enumerate(roles):\n",
    "                                if (rol==\"manager\"):\n",
    "                                    tuple.append(i)\n",
    "\n",
    "                            constraints[container_index]=tuple\n",
    "                        elif (\"worker\" in constraint):\n",
    "\n",
    "                            for i,rol in enumerate(roles):\n",
    "                                if (rol==\"worker\"):\n",
    "                                    tuple.append(i)\n",
    "\n",
    "\n",
    "                            constraints[container_index]=tuple\n",
    "\n",
    "\n",
    "        return(constraints)\n",
    "\n",
    "\n",
    "    def createjson(self,machines,containers,initial_state,images,dependencies,constraints,roles):\n",
    "        machines_IDS=self.get_nodes_Id()\n",
    "\n",
    "        with open(r'instanceExamples/data.json', mode='w', encoding='utf-8') as file:\n",
    "\n",
    "            nodes=[]\n",
    "            cons=[]\n",
    "            dep=[]\n",
    "            entry = {}\n",
    "            for i,n in enumerate(machines):\n",
    "                if roles[i]==\"manager\":\n",
    "\n",
    "                    one_node = {'id':i,'name': n,\"Manager Status\": \"Leader\",\"cluster_id\":machines_IDS[i],\"activated\": 'true', \"max_power_consumption\": 1030, \"Maxmem\":0}\n",
    "                    nodes.append(one_node)\n",
    "                else:\n",
    "                    one_node = {'id':i,'name': n,\"Manager Status\": \"worker\",\"cluster_id\":machines_IDS[i],\"activated\": 'true', \"max_power_consumption\": 1030, \"Maxmem\":0}\n",
    "                    nodes.append(one_node)\n",
    "                    \n",
    "            for i,n in enumerate(containers):\n",
    "\n",
    "                one_container ={'id':i,'name': n,'image':images[i],'dependencies':[],'placements':[],\"priority\": 4,\"average_power_consumption_per_minute\": 30, \"power_consumption\": 50, \"cpu_usage\": 5.14109452666673405, \"mem_usage\": 10.13}\n",
    "                print(one_container['dependencies'])\n",
    "                cons.append(one_container)\n",
    "\n",
    "            for i,dep in enumerate(dependencies):\n",
    "            #print(cons[dep[0]].dependencies)\n",
    "\n",
    "                cons[dep[0]]['dependencies'].append(dep[1])\n",
    "\n",
    "\n",
    "            entry['nodes']=nodes\n",
    "            entry['currentState']=initial_state\n",
    "            entry['containers']=cons\n",
    "            entry['objectives']=[{\"0\": 0.25}, {\"1\": 0.25}, {\"6\": 0.25}, {\"7\": 0.25}, {\"8\": 1}]\n",
    "            json.dump(entry, file)\n",
    "        return('done')\n",
    "\n",
    "def GetAllData():\n",
    "    data=Data()\n",
    "    images,containers,roles,initial_state,machines=data.get_data()\n",
    "    machines_IDS=data.get_nodes_Id()\n",
    "    print(machines_IDS)\n",
    "    print(roles)\n",
    "    print(containers)\n",
    "    dependencies=data.get_dependencies(images,containers)\n",
    "    print(dependencies)\n",
    "    #print(data.get_constraints(machines, roles, images))\n",
    "    data.createjson(machines,containers,initial_state,images,dependencies,[[] for i in range(len(containers))],roles)\n",
    "    \n",
    "GetAllData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae0ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
